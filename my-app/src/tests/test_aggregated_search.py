"""å¤šæºèšåˆæœç´¢å·¥å…·çš„æµ‹è¯•"""

import sys
from pathlib import Path
from unittest.mock import Mock, patch, MagicMock

import pytest

# æ·»åŠ  src åˆ°è·¯å¾„
src_dir = Path(__file__).parent.parent
if str(src_dir) not in sys.path:
    sys.path.insert(0, str(src_dir))

from tools import paper_tools
from tools.paper_tools import (
    AggregatedSearchInput,
    normalize_title,
    title_similarity,
    deduplicate_papers,
)

# è·å–åº•å±‚å‡½æ•°
search_papers_aggregated = paper_tools.search_papers_aggregated.func


class TestAggregatedSearchInput:
    """æµ‹è¯•èšåˆæœç´¢è¾“å…¥æ¨¡å‹"""

    def test_valid_basic_input(self):
        """æµ‹è¯•åŸºæœ¬æœ‰æ•ˆè¾“å…¥"""
        input_data = AggregatedSearchInput(query="deep learning")
        assert input_data.query == "deep learning"
        assert input_data.max_results_per_source == 5
        assert input_data.sources == ["openalex", "arxiv", "semantic_scholar"]
        assert input_data.deduplicate is True
        assert input_data.timeout_per_source == 30

    def test_custom_sources(self):
        """æµ‹è¯•è‡ªå®šä¹‰æ•°æ®æº"""
        input_data = AggregatedSearchInput(
            query="test",
            sources=["openalex", "arxiv"]
        )
        assert len(input_data.sources) == 2
        assert "semantic_scholar" not in input_data.sources

    def test_max_results_validation(self):
        """æµ‹è¯• max_results_per_source éªŒè¯"""
        # æœ‰æ•ˆå€¼
        input_data = AggregatedSearchInput(query="test", max_results_per_source=1)
        assert input_data.max_results_per_source == 1

        input_data = AggregatedSearchInput(query="test", max_results_per_source=20)
        assert input_data.max_results_per_source == 20

        # æ— æ•ˆå€¼åº”è¯¥æŠ›å‡ºå¼‚å¸¸
        with pytest.raises(Exception):
            AggregatedSearchInput(query="test", max_results_per_source=0)

        with pytest.raises(Exception):
            AggregatedSearchInput(query="test", max_results_per_source=21)


class TestHelperFunctions:
    """æµ‹è¯•è¾…åŠ©å‡½æ•°"""

    def test_normalize_title(self):
        """æµ‹è¯•æ ‡é¢˜æ ‡å‡†åŒ–"""
        assert normalize_title("Deep Learning") == "deep learning"
        assert normalize_title("Deep-Learning!") == "deeplearning"
        assert normalize_title("Deep  Learning") == "deep learning"
        assert normalize_title("") == ""
        assert normalize_title(None) == ""

    def test_title_similarity(self):
        """æµ‹è¯•æ ‡é¢˜ç›¸ä¼¼åº¦è®¡ç®—"""
        # å®Œå…¨ç›¸åŒ
        similarity = title_similarity(
            "Deep Learning for Computer Vision",
            "Deep Learning for Computer Vision"
        )
        assert similarity == 1.0

        # éå¸¸ç›¸ä¼¼ï¼ˆåªæœ‰æ ‡ç‚¹ç¬¦å·ä¸åŒï¼‰
        similarity = title_similarity(
            "Deep Learning for Computer Vision",
            "Deep Learning for Computer-Vision!"
        )
        assert similarity > 0.9

        # å®Œå…¨ä¸åŒ
        similarity = title_similarity(
            "Deep Learning",
            "Quantum Computing"
        )
        assert similarity < 0.5

        # ç©ºå­—ç¬¦ä¸²
        assert title_similarity("", "") == 0.0
        assert title_similarity("test", "") == 0.0

    def test_deduplicate_papers(self):
        """æµ‹è¯•è®ºæ–‡å»é‡"""
        papers = [
            {"title": "Paper A", "doi": "10.1234/a", "arxiv_id": None},
            {"title": "Paper A", "doi": "10.1234/a", "arxiv_id": None},  # é‡å¤ï¼ˆç›¸åŒ DOIï¼‰
            {"title": "Paper B", "doi": None, "arxiv_id": "2301.12345"},
            {"title": "Paper B", "doi": None, "arxiv_id": "2301.12345"},  # é‡å¤ï¼ˆç›¸åŒ ArXiv IDï¼‰
            {"title": "Paper C", "doi": None, "arxiv_id": None},
            {"title": "Paper-C!", "doi": None, "arxiv_id": None},  # é‡å¤ï¼ˆæ ‡é¢˜ç›¸ä¼¼ï¼‰
            {"title": "Paper D", "doi": None, "arxiv_id": None},
        ]

        unique = deduplicate_papers(papers)
        
        # åº”è¯¥å»æ‰ 3 ä¸ªé‡å¤é¡¹
        assert len(unique) == 4
        
        # éªŒè¯ä¿ç•™çš„è®ºæ–‡
        titles = [p["title"] for p in unique]
        assert "Paper A" in titles
        assert "Paper B" in titles
        assert "Paper D" in titles


class TestAggregatedSearch:
    """æµ‹è¯•èšåˆæœç´¢åŠŸèƒ½"""

    @patch('tools.paper_tools.search_papers_openalex')
    @patch('tools.paper_tools.search_papers_ArXiv')
    @patch('tools.paper_tools.search_papers_semantic_scholar')
    def test_basic_aggregated_search(self, mock_ss, mock_arxiv, mock_openalex):
        """æµ‹è¯•åŸºæœ¬èšåˆæœç´¢"""
        # æ¨¡æ‹Ÿä¸‰ä¸ªæ•°æ®æºçš„è¿”å›ç»“æœ
        mock_openalex.func = Mock(return_value="# ğŸ“š æ‰¾åˆ° 2 ç¯‡è®ºæ–‡\n\n## 1. Paper from OpenAlex\n")
        mock_arxiv.func = Mock(return_value="# ğŸ“š æ‰¾åˆ° 1 ç¯‡è®ºæ–‡\n\n## 1. Paper from ArXiv\n")
        mock_ss.func = Mock(return_value="# ğŸ“š æ‰¾åˆ° 1 ç¯‡è®ºæ–‡\n\n## 1. Paper from Semantic Scholar\n")

        result = search_papers_aggregated(
            query="deep learning",
            max_results_per_source=5
        )

        # éªŒè¯ç»“æœåŒ…å«å…³é”®ä¿¡æ¯
        assert "å¤šæºèšåˆæœç´¢ç»“æœ" in result
        assert "deep learning" in result
        assert "OpenAlex" in result or "openalex" in result
        assert "ArXiv" in result or "arxiv" in result
        assert "Semantic Scholar" in result or "semantic_scholar" in result

    @patch('tools.paper_tools.search_papers_openalex')
    @patch('tools.paper_tools.search_papers_ArXiv')
    @patch('tools.paper_tools.search_papers_semantic_scholar')
    def test_custom_sources(self, mock_ss, mock_arxiv, mock_openalex):
        """æµ‹è¯•åªæŸ¥è¯¢æŒ‡å®šçš„æ•°æ®æº"""
        mock_openalex.func = Mock(return_value="# ğŸ“š æ‰¾åˆ° 1 ç¯‡è®ºæ–‡\n\n## 1. Paper\n")
        mock_arxiv.func = Mock(return_value="# ğŸ“š æ‰¾åˆ° 1 ç¯‡è®ºæ–‡\n\n## 1. Paper\n")
        mock_ss.func = Mock(return_value="# ğŸ“š æ‰¾åˆ° 1 ç¯‡è®ºæ–‡\n\n## 1. Paper\n")

        result = search_papers_aggregated(
            query="test",
            sources=["openalex", "arxiv"]  # åªæŸ¥è¯¢ä¸¤ä¸ªæº
        )

        # OpenAlex å’Œ ArXiv åº”è¯¥è¢«è°ƒç”¨
        assert mock_openalex.func.called or "OpenAlex" in result
        
        # Semantic Scholar ä¸åº”è¯¥å‡ºç°åœ¨ç»“æœä¸­ï¼ˆé™¤éé»˜è®¤å€¼æœ‰å˜åŒ–ï¼‰
        # æ³¨æ„ï¼šç”±äºå®ç°ä¸­å¯èƒ½ä¼šæ˜¾ç¤ºæ‰€æœ‰é…ç½®çš„æºï¼Œæˆ‘ä»¬ä¸»è¦éªŒè¯åŠŸèƒ½æ­£å¸¸

    @patch('tools.paper_tools.search_papers_openalex')
    @patch('tools.paper_tools.search_papers_ArXiv')
    @patch('tools.paper_tools.search_papers_semantic_scholar')
    def test_partial_failure(self, mock_ss, mock_arxiv, mock_openalex):
        """æµ‹è¯•éƒ¨åˆ†æ•°æ®æºå¤±è´¥çš„æƒ…å†µ"""
        # æ¨¡æ‹Ÿ OpenAlex æˆåŠŸï¼Œå…¶ä»–å¤±è´¥
        mock_openalex.func = Mock(return_value="# ğŸ“š æ‰¾åˆ° 2 ç¯‡è®ºæ–‡\n\n## 1. Paper\n")
        mock_arxiv.func = Mock(side_effect=Exception("ArXiv API å¤±è´¥"))
        mock_ss.func = Mock(side_effect=Exception("Semantic Scholar API å¤±è´¥"))

        result = search_papers_aggregated(
            query="test",
            max_results_per_source=5
        )

        # åº”è¯¥åŒ…å«æˆåŠŸå’Œå¤±è´¥çš„ä¿¡æ¯
        assert "å¤šæºèšåˆæœç´¢ç»“æœ" in result or "æœç´¢" in result
        # è‡³å°‘æœ‰ä¸€ä¸ªæºæˆåŠŸï¼Œæ‰€ä»¥ä¸åº”è¯¥æ˜¯å…¨éƒ¨å¤±è´¥
        assert "æ‰€æœ‰æ•°æ®æºæŸ¥è¯¢å¤±è´¥" not in result

    @patch('tools.paper_tools.search_papers_openalex')
    @patch('tools.paper_tools.search_papers_ArXiv')
    @patch('tools.paper_tools.search_papers_semantic_scholar')
    def test_all_sources_fail(self, mock_ss, mock_arxiv, mock_openalex):
        """æµ‹è¯•æ‰€æœ‰æ•°æ®æºéƒ½å¤±è´¥çš„æƒ…å†µ"""
        # æ¨¡æ‹Ÿæ‰€æœ‰æºéƒ½å¤±è´¥
        mock_openalex.func = Mock(side_effect=Exception("å¤±è´¥"))
        mock_arxiv.func = Mock(side_effect=Exception("å¤±è´¥"))
        mock_ss.func = Mock(side_effect=Exception("å¤±è´¥"))

        result = search_papers_aggregated(
            query="test",
            max_results_per_source=5
        )

        # åº”è¯¥è¿”å›æ‰€æœ‰å¤±è´¥çš„é”™è¯¯ä¿¡æ¯
        assert "æ‰€æœ‰æ•°æ®æºæŸ¥è¯¢å¤±è´¥" in result or "å¤±è´¥" in result

    def test_deduplicate_parameter(self):
        """æµ‹è¯•å»é‡å‚æ•°"""
        # æµ‹è¯•å»é‡å¼€å¯
        input_data = AggregatedSearchInput(
            query="test",
            deduplicate=True
        )
        assert input_data.deduplicate is True

        # æµ‹è¯•å»é‡å…³é—­
        input_data = AggregatedSearchInput(
            query="test",
            deduplicate=False
        )
        assert input_data.deduplicate is False


if __name__ == "__main__":
    pytest.main([__file__, "-v"])
